# ğŸ“„ Document Summarizer Pipeline (Local & Serverless-ready)

This project summarizes text content from PDF, DOCX, and TXT files using a free, local Hugging Face model (`t5-small`). It supports both local runs and packaging for AWS Lambda (via Docker).

---

## ğŸ§° Features

- âœ… Text extraction from PDF and DOCX
- âœ… Summarization using a compact Transformers model
- âœ… Manual run on local files or S3 bucket contents
- âœ… Docker-based build for Lambda Layer packaging (Torch + Transformers)

---

## ğŸ—ï¸ Project Structure

```
doc-summarizer-pipeline/
â”œâ”€â”€ extractor/
â”‚   â”œâ”€â”€ pdf_extractor.py
â”‚   â””â”€â”€ docx_extractor.py
â”œâ”€â”€ summarizer.py
â”œâ”€â”€ dynamodb_writer.py
â”œâ”€â”€ run_local_pipeline.py
â”œâ”€â”€ lambda_function.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ requirements-docker.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ .dockerignore
â””â”€â”€ tests/
```

---

## ğŸ§ª Testing

Use `pytest` to test extractors, summarizer, and DynamoDB writer.

```bash
pytest tests/
```

---

## ğŸ³ Build Lambda Layer with Docker (Optional)

To bundle `transformers`, `torch`, and `sentencepiece` into a Lambda-compatible layer:

```bash
# Build image
docker build -t lambda-layer-builder .

# Copy zip from container to host
docker run --rm -v "%cd%:/lambda" --entrypoint /bin/bash lambda-layer-builder -c "cp /lambda/lambda-layer.zip /lambda/"
```

---

## ğŸš€ Local Usage

You can test the pipeline manually with:

```bash
python run_local_pipeline.py
```

---

Let me know if you'd like to add deployment steps, S3 trigger setup, or layer publishing instructions.

